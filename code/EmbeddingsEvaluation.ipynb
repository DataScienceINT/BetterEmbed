{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5389dd5-7abb-4727-8afe-666ffd068a1f",
   "metadata": {},
   "source": [
    "# Define evaluator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5a451c-986c-4a5c-830e-d5a0a3010fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from embeddings_training import ContrastiveAutoencoder\n",
    "import numpy as np \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import json\n",
    "import torch\n",
    "\n",
    "class EmbeddingEvaluator:\n",
    "    def __init__(self, model_type, model_path=None, embedding_model_name=None, k=5):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator with the specified model type.\n",
    "        :param model_type: Either 'custom' for a trained model or 'pretrained' for a SentenceTransformer model.\n",
    "        :param model_path: Path to the trained model (for custom model).\n",
    "        :param embedding_model_name: Name of the pre-trained SentenceTransformer model (for pretrained model).\n",
    "        :param k: Number of top passages to retrieve.\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.k = k\n",
    "        self.metrics_store = []\n",
    "        \n",
    "        # Load the appropriate model based on model type\n",
    "        if model_type == \"custom\":\n",
    "            self.model = ContrastiveAutoencoder.from_pretrained(model_path)  # Load custom model\n",
    "        elif model_type == \"pretrained\":\n",
    "            self.embedding_model_name = embedding_model_name\n",
    "            self.model = SentenceTransformer(embedding_model_name)  # Load SentenceTransformer model\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "\n",
    "    def load_dataset(self, file_path):\n",
    "        \"\"\"\n",
    "        Load dataset from JSON file and return questions and answers.\n",
    "        :param file_path: Path to the JSON dataset file.\n",
    "        :return: Tuple of (questions, answers)\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        questions = []\n",
    "        answers = []\n",
    "\n",
    "        for entry in data.values():\n",
    "            questions.append(entry[\"question\"])\n",
    "            answers.extend(entry[\"answers\"])\n",
    "\n",
    "        return questions, answers\n",
    "\n",
    "    def generate_embeddings(self, texts):\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts using the pre-trained embedding model or custom model.\n",
    "        :param texts: List of text strings.\n",
    "        :return: Embeddings as tensors.\n",
    "        \"\"\"\n",
    "        if self.model_type == \"custom\":\n",
    "            return self.model.encode(texts)  # Custom model's encode method\n",
    "        elif self.model_type == \"pretrained\":\n",
    "            return self.model.encode(texts, convert_to_tensor=True)  # SentenceTransformer's encode method\n",
    "\n",
    "    def retrieve_top_k(self, question_embeddings, answer_embeddings):\n",
    "        \"\"\"\n",
    "        Retrieve the top-k most relevant answers based on cosine similarity.\n",
    "        :param question_embeddings: List of question embeddings.\n",
    "        :param answer_embeddings: List of answer embeddings.\n",
    "        :return: Top-k indices for each question.\n",
    "        \"\"\"\n",
    "        # Check if the embeddings are on GPU and move them to CPU if necessary\n",
    "        if question_embeddings.device != torch.device('cpu'):\n",
    "            question_embeddings = question_embeddings.cpu().detach().numpy()\n",
    "        if answer_embeddings.device != torch.device('cpu'):\n",
    "            answer_embeddings = answer_embeddings.cpu().detach().numpy()\n",
    "    \n",
    "        # Convert to NumPy arrays for cosine similarity calculation\n",
    "        #question_embeddings = question_embeddings.numpy()\n",
    "        #answer_embeddings = answer_embeddings.numpy()\n",
    "\n",
    "        cosine_sim = cosine_similarity(question_embeddings, answer_embeddings)\n",
    "        top_k_indices = np.argsort(cosine_sim, axis=1)[:, ::-1][:, :self.k]\n",
    "        return top_k_indices\n",
    "\n",
    "    def compute_metrics(self, dataset_name, relevant_indices, top_k_indices):\n",
    "        \"\"\"\n",
    "        Compute MRR, Precision@k, and Recall@k for the current dataset.\n",
    "        :param dataset_name: Name or path of the dataset being evaluated.\n",
    "        :param relevant_indices: List of relevant indices (correct answers) for each question.\n",
    "        :param top_k_indices: List of top-k retrieved indices for each question.\n",
    "        :return: Tuple of MRR, Precision@k, and Recall@k.\n",
    "        \"\"\"\n",
    "        mrr = self.mean_reciprocal_rank(relevant_indices, top_k_indices)\n",
    "        precision = self.precision_at_k(relevant_indices, top_k_indices)\n",
    "        recall = self.recall_at_k(relevant_indices, top_k_indices)\n",
    "\n",
    "        # Store the metrics for this dataset\n",
    "        self.metrics_store.append({\n",
    "            \"Model\": self.model_type if self.model_type == \"custom\" else self.embedding_model_name,\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"MRR\": mrr,\n",
    "            \"Precision@k\": precision,\n",
    "            \"Recall@k\": recall\n",
    "        })\n",
    "\n",
    "        return mrr, precision, recall\n",
    "\n",
    "    def mean_reciprocal_rank(self, relevant_indices, top_k_indices):\n",
    "        mrr_total = 0.0\n",
    "        for i, relevant in enumerate(relevant_indices):\n",
    "            for rank, retrieved in enumerate(top_k_indices[i]):\n",
    "                if retrieved in relevant:\n",
    "                    mrr_total += 1.0 / (rank + 1)\n",
    "                    break\n",
    "        return mrr_total / len(relevant_indices)\n",
    "\n",
    "    def precision_at_k(self, relevant_indices, top_k_indices):\n",
    "        precision_total = 0.0\n",
    "        for i, relevant in enumerate(relevant_indices):\n",
    "            retrieved_set = set(top_k_indices[i][:self.k])\n",
    "            relevant_set = set(relevant)\n",
    "            precision_total += len(retrieved_set.intersection(relevant_set)) / self.k\n",
    "        return precision_total / len(relevant_indices)\n",
    "\n",
    "    def recall_at_k(self, relevant_indices, top_k_indices):\n",
    "        recall_total = 0.0\n",
    "        for i, relevant in enumerate(relevant_indices):\n",
    "            retrieved_set = set(top_k_indices[i][:self.k])\n",
    "            relevant_set = set(relevant)\n",
    "            recall_total += len(retrieved_set.intersection(relevant_set)) / len(relevant_set)\n",
    "        return recall_total / len(relevant_indices)\n",
    "\n",
    "    def evaluate(self, dataset_file_paths):\n",
    "        \"\"\"\n",
    "        Evaluate the embedding model on multiple datasets and compute metrics for each.\n",
    "        :param dataset_file_paths: List of dataset file paths.\n",
    "        \"\"\"\n",
    "        for dataset_file_path in dataset_file_paths:\n",
    "            questions, answers = self.load_dataset(dataset_file_path)\n",
    "\n",
    "            # Generate embeddings for questions and answers\n",
    "            question_embeddings = self.generate_embeddings(questions)\n",
    "            answer_embeddings = self.generate_embeddings(answers)\n",
    "\n",
    "            # Retrieve the top-k results for each question\n",
    "            top_k_indices = self.retrieve_top_k(question_embeddings, answer_embeddings)\n",
    "\n",
    "            # Generate relevant indices (assuming you have the correct answer indices)\n",
    "            relevant_indices = self.get_relevant_indices(dataset_file_path, answers)\n",
    "\n",
    "            # Compute and return the evaluation metrics for the current dataset\n",
    "            mrr, precision, recall = self.compute_metrics(dataset_file_path, relevant_indices, top_k_indices)\n",
    "            print(f\"Dataset: {dataset_file_path}, MRR: {mrr:.3f}, Precision@{self.k}: {precision:.3f}, Recall@{self.k}: {recall:.3f}\")\n",
    "\n",
    "    def get_relevant_indices(self, dataset_file_path, answers):\n",
    "        \"\"\"\n",
    "        Get the relevant indices (correct answers) for each question.\n",
    "        :param dataset_file_path: Path to the dataset file.\n",
    "        :param answers: List of all possible answers.\n",
    "        :return: List of relevant indices for each question.\n",
    "        \"\"\"\n",
    "        with open(dataset_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        relevant_indices = []\n",
    "        for entry in data.values():\n",
    "            relevant = [answers.index(ans) for ans in entry[\"answers\"]]\n",
    "            relevant_indices.append(relevant)\n",
    "\n",
    "        return relevant_indices\n",
    "\n",
    "    def get_metrics_summary(self):\n",
    "        \"\"\"\n",
    "        Retrieve the stored metrics across all evaluated datasets.\n",
    "        :return: List of metric dictionaries for each dataset.\n",
    "        \"\"\"\n",
    "        return self.metrics_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3c6297-6acf-469a-b845-0332ae3885fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator usage function\n",
    "def evaluate_model(datasets,model_type, model_path=None, embedding_model_name=None, k=5):\n",
    "    # Initialize the evaluator with a pre-trained Sentence-BERT model\n",
    "    evaluator = EmbeddingEvaluator(model_type, model_path=model_path, embedding_model_name=embedding_model_name, k=k)\n",
    "\n",
    "    # Evaluate the model on all datasets\n",
    "    evaluator.evaluate(datasets)\n",
    "\n",
    "    # Retrieve stored metrics\n",
    "    return(evaluator.get_metrics_summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a60cc5-176a-4bea-b36a-01c126dd1ab1",
   "metadata": {},
   "source": [
    "# Evaluate embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "780b8d4a-0d9d-451e-ba46-f743ecc330e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['/home/mcorradi/researchdrive/BetterEmbedData/bioasq_test_set.json', '/home/mcorradi/researchdrive/BetterEmbedData/pubmedqa_test_set.json']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c09f01f-762a-43ba-8196-9516e09d2867",
   "metadata": {},
   "source": [
    "The BioASQ test set dataset is a random 20% extract for the BioQSA dataset 12b, it contained about a 1000 questions and their corresponding answers.\n",
    "The PubMedQA test set dataset is the entire PubMed QA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5f673-1d9d-4943-b858-0d7e9c74978d",
   "metadata": {},
   "source": [
    "## General model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d885105a-e3a6-42e8-b44d-351027101b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: /home/mcorradi/researchdrive/BetterEmbedData/bioasq_test_set.json, MRR: 0.932, Precision@5: 0.721, Recall@5: 0.549\n",
      "Dataset: /home/mcorradi/researchdrive/BetterEmbedData/pubmedqa_test_set.json, MRR: 0.925, Precision@5: 0.192, Recall@5: 0.958\n"
     ]
    }
   ],
   "source": [
    "metrics_general = evaluate_model(datasets,model_type='pretrained',embedding_model_name = 'BAAI/bge-base-en-v1.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e3cab-2ae6-402a-9119-a4247931ec1f",
   "metadata": {},
   "source": [
    "## PubMed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b8dee-eef6-486a-9910-3877cd8cb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pubmed = evaluate_model(datasets,model_type='pretrained',embedding_model_name = 'neuml/pubmedbert-base-embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb95585-1dd3-4970-81dc-cd42620726a1",
   "metadata": {},
   "source": [
    "## BetterEmbed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbaec14-2dc6-4db7-b36c-71b7ee5bf1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bioqa_contrastive_2 were not used when initializing ContrastiveAutoencoder: ['embedding_model.0.auto_model.embeddings.LayerNorm.bias', 'embedding_model.0.auto_model.embeddings.LayerNorm.weight', 'embedding_model.0.auto_model.embeddings.position_embeddings.weight', 'embedding_model.0.auto_model.embeddings.token_type_embeddings.weight', 'embedding_model.0.auto_model.embeddings.word_embeddings.weight', 'embedding_model.0.auto_model.encoder.layer.0.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.0.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.0.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.0.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.0.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.0.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.0.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.0.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.0.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.0.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.0.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.0.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.0.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.0.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.0.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.0.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.1.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.1.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.1.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.1.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.1.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.1.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.1.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.1.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.1.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.1.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.1.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.1.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.1.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.1.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.1.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.1.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.10.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.10.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.10.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.10.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.10.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.10.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.10.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.10.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.10.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.10.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.10.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.10.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.10.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.10.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.11.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.11.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.11.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.11.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.11.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.11.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.11.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.11.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.11.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.11.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.11.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.11.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.11.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.11.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.2.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.2.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.2.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.2.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.2.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.2.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.2.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.2.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.2.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.2.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.2.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.2.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.2.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.2.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.2.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.2.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.3.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.3.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.3.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.3.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.3.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.3.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.3.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.3.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.3.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.3.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.3.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.3.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.3.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.3.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.3.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.3.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.4.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.4.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.4.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.4.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.4.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.4.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.4.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.4.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.4.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.4.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.4.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.4.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.4.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.4.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.4.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.4.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.5.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.5.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.5.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.5.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.5.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.5.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.5.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.5.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.5.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.5.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.5.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.5.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.5.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.5.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.6.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.6.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.6.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.6.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.6.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.6.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.6.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.6.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.6.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.6.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.6.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.6.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.6.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.6.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.7.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.7.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.7.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.7.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.7.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.7.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.7.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.7.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.7.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.7.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.7.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.7.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.7.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.7.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.8.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.8.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.8.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.8.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.8.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.8.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.8.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.8.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.8.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.8.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.8.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.8.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.8.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.8.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.9.attention.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.9.attention.output.dense.weight', 'embedding_model.0.auto_model.encoder.layer.9.attention.self.key.bias', 'embedding_model.0.auto_model.encoder.layer.9.attention.self.key.weight', 'embedding_model.0.auto_model.encoder.layer.9.attention.self.query.bias', 'embedding_model.0.auto_model.encoder.layer.9.attention.self.query.weight', 'embedding_model.0.auto_model.encoder.layer.9.attention.self.value.bias', 'embedding_model.0.auto_model.encoder.layer.9.attention.self.value.weight', 'embedding_model.0.auto_model.encoder.layer.9.intermediate.dense.bias', 'embedding_model.0.auto_model.encoder.layer.9.intermediate.dense.weight', 'embedding_model.0.auto_model.encoder.layer.9.output.LayerNorm.bias', 'embedding_model.0.auto_model.encoder.layer.9.output.LayerNorm.weight', 'embedding_model.0.auto_model.encoder.layer.9.output.dense.bias', 'embedding_model.0.auto_model.encoder.layer.9.output.dense.weight', 'embedding_model.0.auto_model.pooler.dense.bias', 'embedding_model.0.auto_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing ContrastiveAutoencoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ContrastiveAutoencoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: /home/mcorradi/researchdrive/BetterEmbedData/bioasq_test_set.json, MRR: 0.424, Precision@5: 0.254, Recall@5: 0.141\n",
      "Dataset: /home/mcorradi/researchdrive/BetterEmbedData/pubmedqa_test_set.json, MRR: 0.475, Precision@5: 0.121, Recall@5: 0.606\n"
     ]
    }
   ],
   "source": [
    "metrics_better = evaluate_model(datasets,model_type='custom',model_path='bioqa_contrastive_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd52ee-f900-4c47-85c7-ff5ddd6f444e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f49a2-ae07-4c20-b3da-64414e733323",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContrastiveAutoencoder.from_pretrained('bioqa_contrastive_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cd1ac-0f22-4a9f-a3eb-890379f88011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings",
   "language": "python",
   "name": "embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
